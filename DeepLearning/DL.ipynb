{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归模型\n",
    "\n",
    "### 线性回归\n",
    "\n",
    "使用线性回归(linear regression)模型可以预测$f_{w,b}(x^{(i)})$:\n",
    "$$f_{w,b}(x^{(i)}) = wx^{(i)} + b \\tag{1}$$\n",
    "通过输入的训练数据来拟合参数 $w$,$b$ 从而最小化预测值 $f_{w,b}(x^{(i)})$ 和实际数据 $y^{(i)}$ 之间的误差。 该度量被称为成本(cost), $J(w,b)$。 在训练过程中会计算所有样本的成本。\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2\\tag{2}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降 \n",
    "\n",
    "梯度下降(gradient descent)被描述为:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline \n",
    " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "其中参数 $w$, $b$ 同时被更新，即先计算偏导再更新参数。其中 $\\alpha$ 是学习率，用来控制梯度下降时的步长。\n",
    "\n",
    "该公式中梯度被定义为:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \\tag{4}\\\\\n",
    "  \\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{5}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "其中 $m$ 是训练样本的数量。\n",
    "\n",
    "梯度下降的缺点是只能求得导数方向，不能求得与最优点的距离，且不能保证全局最优性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多元线性回归\n",
    "\n",
    "多元线性回归模型如下：\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b \\tag{1}$$\n",
    "或者写为向量形式:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b  \\tag{2} $$ \n",
    "其中 $\\cdot$ 表示向量点积。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多元的代价函数 $J(\\mathbf{w},b)$ 为:\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 \\tag{3}$$ \n",
    "其中:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b  \\tag{4} $$ \n",
    "\n",
    "其中 $\\mathbf{w}$ 与 $\\mathbf{x}^{(i)}$ 均为标量而非矢量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多元梯度下降的描述如下:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{5}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "其中 $n$ 为特征数量，参数 $w_j$，$b$ 同时被更新，即先计算偏导再更新参数。其中 $\\alpha$ 是学习率，用来控制梯度下降时的步长。\n",
    "\n",
    "其中梯度的定义为：\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{6}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{7}\n",
    "\\end{align}\n",
    "$$\n",
    "其中 $m$ 为训练样本的数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征缩放\n",
    "\n",
    "通过特征缩放(Feature scaling)可以确保特征在一个相近的范围内，从而使算法更快收敛。\n",
    "\n",
    "可以通过三种方式来进行特征缩放:\n",
    "- 每个特征除以一个选定的值，如特征的绝对值最大值，从而将范围缩放到 $[-1,1]$ 之间。\n",
    "- Mean normalization: 每个特征减去其均值，然后除以最大值与最小值之差，即 $x_i = \\dfrac{x_i - \\mu_i}{max - min} $ \n",
    "- Z-score normalization: 每个特征减去其均值，然后除以标准差，即 $x_i = \\dfrac{x_i - \\mu_i}{\\sigma_i} $\n",
    "\n",
    "#### Z-score normalization\n",
    "\n",
    "在 Z-score normalization 之后，所有特征的平均值为 0，标准差为 1。\n",
    "\n",
    "该标准化的过程如下：\n",
    "\n",
    "$$\n",
    "x^{(i)}_j = \\dfrac{x^{(i)}_j - \\mu_j}{\\sigma_j}\n",
    "$$ \n",
    "其中 $j$ 是特征的索引，$µ_j$ 是该特征的均值 $\\sigma_j$ 是该特征的标准差。\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mu_j &= \\frac{1}{m} \\sum_{i=0}^{m-1} x^{(i)}_j\\\\\n",
    "\\sigma^2_j &= \\frac{1}{m} \\sum_{i=0}^{m-1} (x^{(i)}_j - \\mu_j)^2 \n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习率的选择\n",
    "\n",
    "如果在一次迭代中成本函数的值减少的值小于一个很小的值 $\\varepsilon$，如 $0.001$，我们可以认为梯度下降已经收敛。可以根据迭代次数-成本函数的图像来选择学习率，从而获得能够快速收敛的学习率。\n",
    "\n",
    "通常可以使用 $0.001,0.003,0.1,0.3,1\\cdots$ 等值来进行尝试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征工程\n",
    "\n",
    "特征工程即通过转换或者组合特征来创建新的特征。例如，长度和宽度可以组合成面积，从而创建一个新的特征。然后根据原有特征和新特征来进行训练，从而让学习算法做出更好的预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多项式回归\n",
    "\n",
    "多项式回归是线性回归的一种扩展，通过将特征进行多项式转换，从而可以拟合非线性的数据。例如，通过将特征 $x$ 转换为 $x^2$ 或者 $x^3$ 等，从而可以拟合二次或者三次曲线。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归\n",
    "\n",
    "逻辑回归(logistic regression)是一种用于解决分类问题的线性模型。逻辑回归的输出是一个概率值，用来表示样本属于某个类别的概率。\n",
    "\n",
    "逻辑回归的模型如下： \n",
    "\n",
    "$$\n",
    "f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(\\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b) \\tag{1}\n",
    "$$\n",
    "对于逻辑回归模型，$z=\\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b$，故 $g(z)$ 为激活函数(sigmoid function)，其将所有的输入值映射到 $[0,1]$ 之间:\n",
    "\n",
    "$$\n",
    "g(z) = \\frac{1}{1+e^{-z}} \\tag{2}\n",
    "$$\n",
    "\n",
    "- 如果 $f_{\\mathbf{w},b}(x) >= 0.5$，即 $z\\ge 0$，则预测 $y=1$\n",
    "- 如果 $f_{\\mathbf{w},b}(x) < 0.5$，即 $z\\lt 0$，则预测 $y=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策边界\n",
    "\n",
    "根据拟合出的参数 $\\mathbf{w}$ 和 $b$，可以绘制出决策边界(decision boundary)，决策边界的坐标轴为特征的维度，通过绘制决策边界，可以直观的看出模型的分类效果。决策边界可以是线性的，也可以是非线性的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逻辑回归的代价函数\n",
    "\n",
    "逻辑回归的代价函数 $J(\\mathbf{w},b)$ 为:\n",
    "\n",
    "$$\n",
    "J(\\mathbf{w},b) = \\frac{1}{m} \\sum_{i=0}^{m-1} \\left[ loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right] \\tag{1}\n",
    "$$\n",
    "\n",
    "其中：\n",
    "$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)})$ 为损失函数，用来衡量预测值 $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ 与实际值 $y^{(i)}$ 之间的差异。逻辑回归的损失函数为:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) &= -y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\newline &- \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\tag{2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "对于该损失函数，当 $y^{(i)}=0$ 时，第一项为 $0$，第二项为 $-\\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right)$，当 $f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\to 1$ 时，损失函数趋近于 $0$；当 $y^{(i)}=1$ 时，第一项为 $-\\log \\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right)$，第二项为 $0$，当 $f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\to 0$ 时，损失函数趋近于 $0$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逻辑回归的梯度下降\n",
    "\n",
    "逻辑回归的梯度下降的描述如下:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "其中 $n$ 为特征数量，参数 $w_j$，$b$ 同时被更新，即先计算偏导再更新参数。其中 $\\alpha$ 是学习率，用来控制梯度下降时的步长。\n",
    "\n",
    "其中梯度的定义为：\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{2}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{3}\n",
    "\\end{align}\n",
    "$$\n",
    "其中 $m$ 为训练样本的数量。\n",
    "\n",
    "虽然形式上与线性回归的梯度下降相同，但逻辑回归的模型是 $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(\\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b)$，线性回归的模型是 $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正则化\n",
    "\n",
    "在拟合模型时，有时会出现过拟合(overfitting)的情况，即模型在训练集上表现很好，但在测试集上表现很差。过拟合可以通过增加训练样本数量，减少特征数量，或者正则化(regularization)来解决。\n",
    "\n",
    "正则化的原理就是在代价函数中增加惩罚项来减小参数的值，从而防止过拟合。通常的正则化项为 $\\frac{\\lambda}{2m}  \\sum_{j=0}^{n-1} w_j^2$\n",
    "    \n",
    "对于线性回归和逻辑回归，正则化后的梯度为：\n",
    "$$\\begin{align*}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)}  +  \\frac{\\lambda}{m} w_j \\tag{1} \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{2} \n",
    "\\end{align*}$$\n",
    "\n",
    "其中，$\\lambda$ 为正则化参数，用来控制正则化的强度。$m$ 为训练样本的数量。\n",
    "\n",
    "根据梯度下降的步骤：\n",
    "$$\\begin{align*}\n",
    "&\\text{repeat until convergence:} \\; \\lbrace \\\\\n",
    "&  \\; \\; \\;w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1}  \\; & \\text{for j := 0..n-1} \\\\ \n",
    "&  \\; \\; \\;  \\; \\;b = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \\\\\n",
    "&\\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "我们可以提取出：\n",
    "$$\n",
    "\\begin{align*}\n",
    "w_j &= (1 - \\alpha \\frac{\\lambda}{m})w_j -  \\alpha \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{3} \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "根据这个式子，我们可以观察到正则化参数 $\\lambda$ 的作用是每次迭代减小 $w_j$ 的值，从而防止过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络\n",
    "\n",
    "### 激活函数\n",
    "\n",
    "激活函数(activation function)是神经网络中的一个重要组成部分，它决定了神经元的输出。常用的激活函数有 sigmoid 函数、tanh 函数、ReLU 函数等。\n",
    "\n",
    "- sigmoid 函数: $g(z) = \\frac{1}{1+e^{-z}}$，用于二分类问题\n",
    "- ReLU 函数: $g(z) = \\max(0,z)$，用于输出值为非负数的情况\n",
    "- linear 函数: $g(z) = z$，用于输出值为任意实数的情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "\n",
    "Softmax 函数是一种用于多分类问题的激活函数，它将神经元的输出值转换为概率值。Softmax 函数的定义如下：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{softmax}(\\mathbf{z})_i &= \\frac{e^{z_i}}{\\sum_{j=0}^{n-1} e^{z_j}} \\tag{1} \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "其中 $z$ 为神经元的输出值，$n$ 为特征的数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax 的损失函数为交叉熵损失函数(cross-entropy loss function)。交叉熵损失函数的定义如下：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "J(\\mathbf{z}) &= -\\frac{1}{m} \\sum_{i=0}^{m-1} \\sum_{j=0}^{n-1} y^{(i)}_j \\log \\left( \\text{softmax}(\\mathbf{z}^{(i)})_j \\right) \\tag{2}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "其中 $y^{(i)}_j$ 为样本 $i$ 是否属于类别 $j$ 的布尔值。\n",
    "\n",
    "还有稀疏交叉熵损失函数(sparse cross-entropy loss function)，其定义如下：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "J(\\mathbf{z}) &= -\\frac{1}{m} \\sum_{i=0}^{m-1} \\sum_{j=0}^{n-1} 1\\{y^{(i)}== j\\} \\log \\left( \\text{softmax}(\\mathbf{z}^{(i)})_j \\right) \\tag{3}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "其中 $y^{(i)}$ 为样本 $i$ 的实际类型取值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 1s 5ms/step - loss: 1.7868 - val_loss: 1.3745\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 1.2093 - val_loss: 1.1038\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 1.0076 - val_loss: 0.9399\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.8522 - val_loss: 0.7815\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7097 - val_loss: 0.6573\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6088 - val_loss: 0.5797\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5482 - val_loss: 0.5317\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5080 - val_loss: 0.4961\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.4771 - val_loss: 0.4675\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.4515 - val_loss: 0.4432\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.4290 - val_loss: 0.4221\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4090 - val_loss: 0.4026\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.3848\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.3685\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.3581 - val_loss: 0.3530\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.3392\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.3255\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.3167 - val_loss: 0.3131\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3047 - val_loss: 0.3010\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2932 - val_loss: 0.2901\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2828 - val_loss: 0.2800\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2726 - val_loss: 0.2695\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.2631 - val_loss: 0.2600\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.2540 - val_loss: 0.2512\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2444 - val_loss: 0.2407\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2300 - val_loss: 0.2231\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2134 - val_loss: 0.2080\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1990 - val_loss: 0.1904\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1760 - val_loss: 0.1629\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1545 - val_loss: 0.1462\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1440 - val_loss: 0.1391\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1384 - val_loss: 0.1344\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1340 - val_loss: 0.1308\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1304 - val_loss: 0.1274\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1273 - val_loss: 0.1240\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1245 - val_loss: 0.1214\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1221 - val_loss: 0.1187\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1194 - val_loss: 0.1165\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1171 - val_loss: 0.1141\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1153 - val_loss: 0.1120\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1135 - val_loss: 0.1107\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1115 - val_loss: 0.1080\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1096 - val_loss: 0.1061\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.1042\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1062 - val_loss: 0.1028\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1048 - val_loss: 0.1015\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1032 - val_loss: 0.0997\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1020 - val_loss: 0.0988\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0966\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0994 - val_loss: 0.0967\n",
      "WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D30AF31438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "[[-1.35231146 -0.47697014]\n",
      " [-4.50328585  1.8617357 ]]\n",
      "[[0.02864943 0.9022494  0.06154283 0.00755833]\n",
      " [0.9908262  0.0056769  0.00165204 0.00184484]]\n"
     ]
    }
   ],
   "source": [
    "# softmax regression\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "centers = [[-5, 2], [-2, -2], [1, 2], [5, -2]]\n",
    "x_train, y_train = make_blobs(\n",
    "    n_samples=2000, centers=centers, cluster_std=1.0, random_state=30)\n",
    "\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.2,random_state=42)\n",
    "\n",
    "x_test, y_test = make_blobs(\n",
    "    n_samples=2, centers=centers, cluster_std=1.0, random_state=42)\n",
    "\n",
    "\n",
    "model=Sequential([\n",
    "    #kernel_regularizer表示权重的正则化\n",
    "    Dense(units=16,activation='relu',kernel_regularizer=l2(0.01)),\n",
    "    Dense(units=8,activation='relu',kernel_regularizer=l2(0.01)),\n",
    "    Dense(units=4,activation='linear')\n",
    "])\n",
    "\n",
    "# from_logits=True表示未经过softmax层，计算更加稳定\n",
    "# 采用Adam算法进行优化\n",
    "model.compile(loss=SparseCategoricalCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3))\n",
    "# validation_data是交叉验证数据集\n",
    "model.fit(x_train,y_train,epochs=50,validation_data=(x_val,y_val))\n",
    "\n",
    "p = model.predict(x_test)\n",
    "# 进行softmax处理\n",
    "sm = tf.nn.softmax(p).numpy()\n",
    "\n",
    "print(x_test)\n",
    "print(sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 倾斜数据集的误差指标\n",
    "\n",
    "对于倾斜的数据集，即正负样本的数量差异很大的数据集，我们不能使用准确率(accuracy)作为误差指标。因为即使模型预测所有样本都为负样本，也可以获得很高的准确率。例如：某种罕见疾病的检测，正样本占总样本的 $1\\%$，即使模型预测所有样本都为负样本，也可以获得 $99\\%$ 的准确率。\n",
    "\n",
    "对于倾斜的数据集，我们可以使用精确率(precision)和召回率(recall)作为误差指标。精确率和召回率的定义如下：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{precision} &= \\frac{TP}{TP+FP} \\tag{1} \\\\\n",
    "\\text{recall} &= \\frac{TP}{TP+FN} \\tag{2}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "其中 $TP$ 为真正例(true positive)，即模型预测为正样本的样本中实际为正样本的数量，$FP$ 为假正例(false positive)，即模型预测为正样本的样本中实际为负样本的数量，$FN$ 为假负例(false negative)，即模型预测为负样本的样本中实际为正样本的数量。\n",
    "\n",
    "提升精确率可以减少错报，提升召回率可以减少漏报。\n",
    "\n",
    "精确率和召回率是一对矛盾的指标，即提高精确率会降低召回率，提高召回率会降低精确率。我们可以使用 F1 值来综合考虑精确率和召回率，F1 值的定义如下：\n",
    "\n",
    "$$\n",
    "\\text{F1} = \\frac{2}{{\\frac{1}{P}} + \\frac{1}{R}} \\tag{3}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树\n",
    "\n",
    "决策树是一种用于分类和回归的监督学习算法。决策树的目标是通过对特征的提问来预测目标变量的值。决策树的每个非叶节点代表一个特征，每个分支代表一个特征的取值，每个叶子节点代表目标变量的值。\n",
    "\n",
    "决策树根据纯度(purity)来选择特征，我们可以根据熵(entropy)来衡量纯度。熵的定义如下：\n",
    "\n",
    "$$\n",
    "\\text{Entropy} = -\\sum_{i=0}^{n-1} p_i \\log_2 p_i \\tag{1}\n",
    "$$\n",
    "\n",
    "其中 $p_i$ 为类别 $i$ 占当前节点样本数的比例。\n",
    "\n",
    "进一步，我们根据熵的值可以计算出信息增益(information gain)，信息增益的定义如下：\n",
    "\n",
    "$$\n",
    "\\text{Information Gain} = \\text{Entropy(parent)} - \\sum_{i=0}^{n-1} \\frac{N_i}{N} \\text{Entropy(child}_i) \\tag{2}\n",
    "$$\n",
    "\n",
    "其中 $N_i$ 为子节点 $i$ 的样本数量，$N$ 为父节点的样本数量。\n",
    "\n",
    "我们选择信息增益最大的特征进行划分，从而创建树的左右分支，持续划分直到\n",
    "\n",
    "- 一个叶节点纯度为100%，即全为同一种类\n",
    "- 当拆分节点时超过了设定的最大深度\n",
    "- 信息增益小于阈值\n",
    "- 节点中样本数小于阈值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot encoding\n",
    "\n",
    "One-Hot encoding 是一种用于处理分类特征的编码方式。对于分类特征，我们可以使用 One Hot encoding 将其转换为二进制编码。例如，对于特征 $x$，其取值为 $a,b,c$，我们可以将其转换为三个特征 $x_a,x_b,x_c$，其中 $x_a=1$ 表示 $x=a$，$x_b=1$ 表示 $x=b$，$x_c=1$ 表示 $x=c$。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 连续的有价值特征\n",
    "\n",
    "对于连续的有价值特征，我们可以使用决策树来进行划分。例如，对于特征 $x$，我们可以选择一个阈值 $t$，将样本分为 $x<t$ 和 $x\\ge t$ 两部分。我们可以选择信息增益最大的阈值来进行划分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归树\n",
    "\n",
    "除了用于分类，决策树还可以用于回归。对于回归树，我们可以使用方差来衡量纯度，然后使用方差来计算信息增益，计算的方式如下：\n",
    "\n",
    "$$\n",
    "\\text{Variance} = \\frac{1}{N} \\sum_{i=0}^{N-1} (y_i - \\bar{y})^2 \\tag{1}\n",
    "$$\n",
    "\n",
    "其中 $y_i$ 为样本 $i$ 的目标变量的值，$\\bar{y}$ 为所有样本的目标变量的均值。\n",
    "\n",
    "$$\n",
    "\\text{Information Gain} = \\text{Variance(parent)} - \\sum_{i=0}^{n-1} \\frac{N_i}{N} \\text{Variance(child}_i) \\tag{2}\n",
    "$$\n",
    "\n",
    "对于回归树，我们选择信息增益最大的特征进行划分，划分停止的条件与分类树相同，此时预测的值为叶节点中样本的目标变量的均值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机森林\n",
    "\n",
    "随机森林是一种集成学习(ensemble learning)算法，它通过训练多个决策树，然后将它们的预测结果进行平均来提高预测的准确率。随机森林的训练过程如下：\n",
    "\n",
    "- 从训练集中有放回的抽取 $m$ 个样本\n",
    "- 从 $n$ 个特征中随机选择 $k$ 个特征，一般取 $k=\\sqrt{n}$，并保证决策树只从该 $k$ 个特征中选择最佳特征进行划分\n",
    "- 训练决策树\n",
    "- 重复上述步骤 $N$ 次\n",
    "- 对于分类问题，将 $N$ 个决策树的预测结果进行投票，对于回归问题，将 $N$ 个决策树的预测结果进行平均\n",
    "- 得到最终的预测结果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "XGBoost 是一种梯度提升树(gradient boosting tree)算法，其训练过程和随机森林类似，但是其会在训练决策树后对训练集进行预测，然后提高错误样本的权重(抽取的概率)，从而训练下一个决策树。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:05:25] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 0 0 1]\n",
      "[0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "weights=np.random.randint(1,10,size=100)\n",
    "whiskers=np.random.randint(0,2,size=100)\n",
    "faces=np.random.randint(0,3,size=100)\n",
    "hair=np.random.randint(0,5,size=100)\n",
    "targets=np.random.randint(0,2,size=100)\n",
    "\n",
    "data=np.column_stack([weights,whiskers,faces,hair])\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(data,targets,test_size=0.2,random_state=42)\n",
    "\n",
    "# max_depth表示树的最大深度\n",
    "# learning_rate表示学习率\n",
    "# objective表示目标函数，这里是二分类，返回经过sigmoid函数处理的概率\n",
    "model = XGBClassifier(max_depth=3,learning_rate=0.1,objective='binary:logistic')\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "# predict返回的是类别，predict_proba返回的是概率\n",
    "p = model.predict(x_test)\n",
    "\n",
    "print(y_test)\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树的适用场景\n",
    "\n",
    "决策树适用于结构化数据，例如表格，但是其不适用于非结构化数据，例如图像和音频。决策树的优点是易于理解和解释且速度快。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means\n",
    "\n",
    "K-means 是一种无监督学习算法，其目标是将 $n$ 个样本划分为 $k$ 个簇，使得每个样本都属于离其最近的簇。K-means 的训练过程如下：\n",
    "\n",
    "- 随机初始化 $k$ 个簇的中心\n",
    "- 对于每个样本，计算其到 $k$ 个簇中心的距离，将其划分到离其最近的簇\n",
    "- 更新每个簇的中心为其样本的均值\n",
    "- 重复上述步骤直到簇的中心不再变化\n",
    "\n",
    "$c^{(i)}$ 为样本 $i$ 的簇的索引，$\\mu_j$ 为簇 $j$ 的中心，$\\mu_{c^{(i)}}$ 为样本 $i$ 的簇的中心，其中 $k$ 为簇的数量。故 K-means 的代价函数为:\n",
    "\n",
    "$$\n",
    "J(c^{(1)},\\cdots,c^{(m)},\\mu_1,\\cdots,\\mu_k    \n",
    ") = \\frac{1}{m} \\sum_{i=0}^{m-1} ||x^{(i)} - \\mu_{c^{(i)}}||^2 \\tag{1}\n",
    "$$\n",
    "\n",
    "其中 $m$ 为样本的数量。\n",
    "\n",
    "在更新簇的中心时，我们可以使用均值来更新，即:\n",
    "\n",
    "$$\n",
    "\\mu_k = \\frac{1}{|C_k|} \\sum_{i \\in C_k} x^{(i)} \\tag{2}\n",
    "$$\n",
    "\n",
    "其中 $C_k$ 为簇 $k$ 中的样本的索引，$|C_k|$ 为簇 $k$ 中的样本的数量。\n",
    "\n",
    "在初始化 $k$ 个簇的中心时，可以选择样本中的 $k$ 个样本作为初始的簇的中心，多次选择并计算代价函数，选择代价函数最小的一次作为初始的簇的中心。\n",
    "\n",
    "$k$ 的数量应该根据进一步的需求进行选取。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 异常检测算法\n",
    "\n",
    "异常检测算法用于检测数据中的异常值，其使用正态分布来衡量数据的异常程度。对于正态分布，我们可以使用均值 $\\mu$ 和方差 $\\sigma^2$ 来衡量数据的分布。对于样本 $x$，其异常程度为:\n",
    "\n",
    "$$\n",
    "p(x) = \\prod_{j=1}^{n} p(x_j;\\mu_j,\\sigma_j^2) = \\prod_{j=1}^{n} \\frac{1}{\\sqrt{2\\pi}\\sigma_j} \\exp\\left(-\\frac{(x_j-\\mu_j)^2}{2\\sigma_j^2}\\right) \\tag{1}\n",
    "$$\n",
    "\n",
    "对于异常检测算法，我们可以选择一个阈值 $\\varepsilon$，当 $p(x) < \\varepsilon$ 时，我们认为样本 $x$ 为异常值。\n",
    "\n",
    "开发异常检测系统时，可以从带标记(异常或正常)的数据着手，从其中选择一部分正常数据用于构建训练集，然后用剩下的正常数据和异常数据混合的数据构成交叉检验集和测试集。  \n",
    "\n",
    "可以采用以下方式对异常检测系统进行评估：\n",
    "1. 根据训练集数据，我们估计特征的平均值和方差并构建 $p(x)$ 函数;\n",
    "2. 对交叉检验集，尝试使用不同的 $\\varepsilon$ 值作为阀值，并预测数据是否异常，可根据 $F1$ 值来选择 $\\varepsilon$;\n",
    "3. 选出 $\\varepsilon$ 后，对测试集进行预测，计算异常检验系统的F1值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异常检测和监督学习的选择\n",
    "\n",
    "- 对于拥有大量的负向类(y=0)和非常少量的正向类(异常数据 y=1)的数据集，我们选择异常检测算法。对于拥有大量的正向类和大量的负向类的数据集，我们选择监督学习算法。\n",
    "- 未来出现的异常数据与当前的异常数据不同，我们选择异常检测算法。未来出现的异常数据与当前的异常数据相似，我们选择监督学习算法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异常检测的特征选择\n",
    "\n",
    "异常检测算法假设特征满足正态分布，对于不满足正态分布的特征，我们可以使用:\n",
    "\n",
    "- $x=\\log(x+c),x>0$\n",
    "- $x=x^{c},c\\in(0,1)$\n",
    "\n",
    "等方式来转换特征，使其近似满足正态分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推荐系统\n",
    "\n",
    "推荐系统是一种用于预测用户对物品的评分或者喜好的算法。推荐系统的目标是预测用户对物品的评分，然后根据评分来推荐物品。现在我们讨论一个电影预测评分的例子。\n",
    "$r(i,j)$ 表示用户 $j$ 对电影 $i$ 进行了评分。\n",
    "$y(i,j)$ 表示用户 $j$ 对电影 $i$ 的预测评分。\n",
    "$\\mathbf{w}^{(j)}，b^{(j)}$ 为用户 $j$ 的参数。\n",
    "$\\mathbf{x}^{(i)}$ 表示电影 $i$ 的特征向量。\n",
    "$n_u$ 表示用户的数量。\n",
    "$n_m$ 表示电影的数量。\n",
    "$n$ 表示特征的数量。\n",
    "\n",
    "根据电影的特征，我们可以预测用户对电影的评分，预测评分的计算方式如下：\n",
    "\n",
    "$$\n",
    "y(i,j) = \\mathbf{w}^{(j)}\\cdot\\mathbf{x}^{(i)} + b^{(j)} \\tag{1}\n",
    "$$\n",
    "\n",
    "### 协同过滤\n",
    "\n",
    "上述的前提是电影的特征是给出的，可以直接根据电影的特征来预测用户对电影的评分。但是当我们既没有用户的参数也没有电影的特征时，我们可以使用协同过滤(collaborative filtering)来同时学习用户的参数和电影的特征。\n",
    "\n",
    "当给定电影的特征的时候，我们可以使用如下代价函数来学习用户的参数：\n",
    "\n",
    "$$\n",
    "J(\\mathbf{w}^{(1)},\\cdots,\\mathbf{w}^{(n_u)},b^{(1)},\\cdots,b^{(n_u)}) =\\newline \\frac{1}{2} \\sum_{j=1}^{n_u}\\sum_{i:r(i,j)=1} \\left( \\mathbf{w}^{(j)}\\cdot \\mathbf{x}^{(i)} + b^{(j)} - y(i,j) \\right)^2 + \\frac{\\lambda}{2} \\sum_{j=1}^{n_u} \\sum_{k=1}^{n} (\\mathbf{w}^{(j)}_k)^2 \\tag{2}\n",
    "$$\n",
    "\n",
    "当给定用户的参数的时候，我们可以使用如下代价函数来学习电影的特征：\n",
    "\n",
    "$$\n",
    "J(\\mathbf{x}^{(1)},\\cdots,\\mathbf{x}^{(n_m)},b^{(1)},\\cdots,b^{(n_m)}) =\\newline \\frac{1}{2} \\sum_{i=1}^{n_m}\\sum_{i:r(i,j)=1} \\left( \\mathbf{w}^{(j)}\\cdot \\mathbf{x}^{(i)} + b^{(j)} - y(i,j) \\right)^2 + \\frac{\\lambda}{2} \\sum_{i=1}^{n_m} \\sum_{k=1}^{n} (\\mathbf{x}^{(i)}_k)^2 \\tag{3}\n",
    "$$\n",
    "\n",
    "进一步我们可以将它们放在一起，使用如下代价函数来学习用户的参数和偏置参数以及电影的特征：\n",
    "\n",
    "$$\n",
    "J(\\mathbf{w}^{(1)},\\cdots,\\mathbf{w}^{(n_u)},b^{(1)},\\cdots,b^{(n_u)},\\mathbf{X},\\mathbf{R}) =\\newline \\frac{1}{2} \\sum_{(i,j):r(i,j)=1} \\left( (\\mathbf{w}^{(j)})^T \\mathbf{x}^{(i)} + b^{(j)} - r(i,j) \\right)^2 + \\frac{\\lambda}{2} \\sum_{j=1}^{n_u} \\sum_{k=1}^{n} (\\mathbf{w}^{(j)}_k)^2 + \\frac{\\lambda}{2} \\sum_{i=1}^{n_m} \\sum_{k=1}^{n} (\\mathbf{x}^{(i)}_k)^2 \\tag{4}\n",
    "$$\n",
    "\n",
    "协同过滤的目标就是在不断迭代的过程中学习用户参数以及电影的特征，从而使得代价函数最小化。\n",
    "\n",
    "同样我们可以使用梯度下降来求解代价函数的最小值，梯度下降的步骤如下：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{repeat until convergence:} \\; \\lbrace \\\\\n",
    "\\mathbf{w}_k^{(j)} &= \\mathbf{w}_k^{(j)} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{w}_k^{(j)}} \\tag{5} \\\\\n",
    "b^{(j)} &= b^{(j)} - \\alpha \\frac{\\partial J}{\\partial b^{(j)}} \\tag{6} \\\\\n",
    "\\mathbf{x}_k^{(i)} &= \\mathbf{x}_k^{(i)} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{x}_k^{(i)}} \\tag{7} \\\\\n",
    "\\rbrace\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "其中 $\\alpha$ 为学习率，用来控制梯度下降的步长。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 均值归一化\n",
    "\n",
    "在协同过滤中，我们可以使用均值归一化(mean normalization)来处理用户的评分。这样可以保证对新用户评分的预测不会是 $0$，而是用户的平均评分。\n",
    "\n",
    "在均值归一化之后，我们预测用户 $j$ 对电影 $i$ 的评分为:\n",
    "\n",
    "$$\n",
    "y(i,j) = \\mathbf{w}^{(j)}\\cdot\\mathbf{x}^{(i)} + b^{(j)} + \\mu_i \\tag{8}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于内容的过滤\n",
    "\n",
    "基于内容的过滤(content-based filtering)根据用户的特征以及物品的特征来预测用户对物品的评分。其使用神经网络来分别对用户和物品的特征进行学习，最终输出两个向量，这两个向量的内积即为用户对物品的评分。可以使用sigmoid函数来将输出 $y(i,j)$ 为 $1$ 的概率。进一步我们使用这两个向量的内积来计算代价函数，代价函数的定义如下：\n",
    "\n",
    "$$\n",
    "J=\\sum_{(i,j):r(i,j)=1}(\\boldsymbol{v}_{u}\\cdot \\boldsymbol{v}_{m} - y(i,j))^2 + \\text{NN regularization term}\\tag{9}\n",
    "$$\n",
    "\n",
    "\n",
    "我们可以使用获得的 $\\boldsymbol{v}_m$ 来推荐与其相似的电影，即当 $\\left\\vert \\left\\vert \\boldsymbol{v}_{m}^{(k)}-\\boldsymbol{v}_{m}^{(i)} \\right\\vert  \\right\\vert^{2} $ 越小，电影 $k$ 与电影 $i$ 越相似。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在大目录中的推荐\n",
    "\n",
    "因为在大目录中，物品的数量很大，所以我们可以使用以下步骤来进行推荐：\n",
    "\n",
    "1. 遍历生成一组用户可能喜欢的电影，并去重和去除已经看过的电影\n",
    "- 可以根据用于最近看的10部电影来推荐(寻找相似电影)\n",
    "- 可以根据最常看的3类电影选取最好的10部\n",
    "- 选择该用户所在国家最受欢迎的20部电影\n",
    "2. 根据基于内容过滤的模型，对这些电影进行评分并进行排名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 强化学习\n",
    "\n",
    "强化学习的目标是使智能体在环境中学习到一个策略(policy)，使得智能体在环境中获得最大的累积奖励。强化学习的环境可以是离散的，也可以是连续的。\n",
    "\n",
    "强化学习的关键概念在于状态、动作、奖励、折扣因子和策略，我们定义如下状态动作价值函数(Bellman equation)：\n",
    "\n",
    "$$\n",
    "Q(s,a) = R(s)+\\gamma E\\left[\\max_{a'}Q(s',a')\\right] \\tag{1}\n",
    "$$\n",
    "\n",
    "其中 $Q(s,a)$ 为状态 $s$ 采取动作 $a$ 的价值，$R(s)$ 为状态 $s$ 的奖励，$\\gamma$ 为折扣因子，$s'$ 为状态 $s$ 采取动作 $a'$ 后的状态，期望表示采用随机环境。\n",
    "\n",
    "根据价值函数我们就可以得出策略 $\\pi(s)=a$，即在状态 $s$ 采取动作 $a$ 可以得到最大的期望价值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 连续动作空间\n",
    "\n",
    "对于连续动作空间，我们可以使用神经网络来近似价值函数，然后使用梯度下降来更新参数。我们把 $Q(s,a)$ 中的 $s$ 和 $a$ 作为输入 $x$，输出 $y$ 为 $R(s)+\\gamma \\max_{a'}Q(s',a')$，可以采用均方误差作为代价函数。\n",
    "\n",
    "但是因为 $y$ 在每次迭代中都会变化，所以我们使用另一个网络 target $\\hat Q$-Network 来计算目标 $Q$ 值。然后每次使用原有的 Q-network 来预测 $Q$ 值，然后使用这两个值的差计算损失并更新 Q-network 的参数。每个一段时间，我们把 Q-network 的参数复制给 target Q-network，即每一步都在更新 Q-network 的参数，但是每隔一段时间才更新 target Q-network 的参数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 软更新\n",
    "\n",
    "在更新 target Q-network 的参数时，我们可以使用软更新(soft update)的方式，即每次更新 target Q-network 的参数时，我们只更新一小部分参数，这样可以使得 target Q-network 的参数更加稳定，即：\n",
    "\n",
    "$$\n",
    "w_{\\text{target}} = \\tau w_{\\text{local}} + (1-\\tau) w_{\\text{target}} \\tag{2}\n",
    "$$\n",
    "\n",
    "其中 $\\tau$ 为更新速率，$w_{\\text{local}}$ 为 Q-network 的参数，$w_{\\text{target}}$ 为 target Q-network 的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epsilon-greedy 算法\n",
    "\n",
    "在选择动作时，我们可以使用 epsilon-greedy 算法，即以 $\\varepsilon$ 的概率随机选择动作，以 $1-\\varepsilon$ 的概率选择价值最大的动作。初始化时，我们可以设置 $\\varepsilon$ 为一个较大的值，然后随着训练的进行逐渐减小 $\\varepsilon$ 的值，这样更有利于选择价值最大的动作(随机化选择，防止陷入局部最优解)。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改进神经网络\n",
    "\n",
    "我们可以在输出层设置多个输出单元，每个输出单元对应一个动作，从而获得每个动作的预期价值，然后选择价值最大的动作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mini-batch\n",
    "\n",
    "在训练神经网络时，我们可以使用 mini-batch 的方式，即每次从经验池中随机抽取一小部分样本进行训练，这样可以使得训练更加稳定。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
